{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set:  0 --------------------\n",
      "Classifier: Nearest Neighbors on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1 21]]\n",
      "Classified incorrectly:  [26] \n",
      "\n",
      "Classifier: Linear SVM on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[17  3]\n",
      " [ 2 18]]\n",
      "Classified incorrectly:  [4, 8, 20, 26, 32] \n",
      "\n",
      "Classifier: RBF SVM on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[18  0]\n",
      " [ 1 21]]\n",
      "Classified incorrectly:  [26] \n",
      "\n",
      "Classifier: Decision Tree on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[17  0]\n",
      " [ 2 21]]\n",
      "Classified incorrectly:  [10, 26] \n",
      "\n",
      "Classifier: Random Forest on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[18  3]\n",
      " [ 1 18]]\n",
      "Classified incorrectly:  [8, 12, 26, 33] \n",
      "\n",
      "Classifier: AdaBoost on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[18  2]\n",
      " [ 1 19]]\n",
      "Classified incorrectly:  [8, 26, 35] \n",
      "\n",
      "Classifier: Naive Bayes on Data Set: 0\n",
      "Confusion Matrix: \n",
      "[[17  3]\n",
      " [ 2 18]]\n",
      "Classified incorrectly:  [4, 8, 20, 26, 32] \n",
      "\n",
      "\n",
      "Answers:\n",
      "Total points classified incorrectly (all classifiers):\n",
      "9\n",
      "Point classified incorrectly by all but one classifier:\n",
      "0\n",
      "Prediciton accuracy using majority voting ensemble prediction(all classifiers):\n",
      "0.925\n",
      "\n",
      "Best set of 4 predictors to use to have highest accuracy: \n",
      "['Random Forest', 'RBF SVM', 'Nearest Neighbors', 'Naive Bayes']\n",
      "\n",
      "\n",
      "\n",
      "Data Set:  1 --------------------\n",
      "Classifier: Nearest Neighbors on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[15  2]\n",
      " [ 1 22]]\n",
      "Classified incorrectly:  [6, 11, 30] \n",
      "\n",
      "Classifier: Linear SVM on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[16 24]\n",
      " [ 0  0]]\n",
      "Classified incorrectly:  [2, 4, 6, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 26, 28, 29, 31, 32, 34, 37] \n",
      "\n",
      "Classifier: RBF SVM on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[16  5]\n",
      " [ 0 19]]\n",
      "Classified incorrectly:  [6, 11, 15, 18, 19] \n",
      "\n",
      "Classifier: Decision Tree on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[13  5]\n",
      " [ 3 19]]\n",
      "Classified incorrectly:  [0, 2, 3, 4, 11, 18, 20, 21] \n",
      "\n",
      "Classifier: Random Forest on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[16  6]\n",
      " [ 0 18]]\n",
      "Classified incorrectly:  [2, 11, 18, 19, 21, 24] \n",
      "\n",
      "Classifier: AdaBoost on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[16  7]\n",
      " [ 0 17]]\n",
      "Classified incorrectly:  [2, 11, 15, 18, 19, 21, 24] \n",
      "\n",
      "Classifier: Naive Bayes on Data Set: 1\n",
      "Confusion Matrix: \n",
      "[[16 12]\n",
      " [ 0 12]]\n",
      "Classified incorrectly:  [2, 4, 8, 11, 15, 18, 19, 22, 24, 31, 32, 37] \n",
      "\n",
      "\n",
      "Answers:\n",
      "Total points classified incorrectly (all classifiers):\n",
      "28\n",
      "Point classified incorrectly by all but one classifier:\n",
      "1\n",
      "Prediciton accuracy using majority voting ensemble prediction(all classifiers):\n",
      "0.768\n",
      "\n",
      "Best set of 4 predictors to use to have highest accuracy: \n",
      "['Random Forest', 'RBF SVM', 'Nearest Neighbors', 'Naive Bayes']\n",
      "\n",
      "\n",
      "\n",
      "Data Set:  2 --------------------\n",
      "Classifier: Nearest Neighbors on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 3 19]]\n",
      "Classified incorrectly:  [4, 5, 11, 18] \n",
      "\n",
      "Classifier: Linear SVM on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[17  1]\n",
      " [ 3 19]]\n",
      "Classified incorrectly:  [4, 5, 11, 24] \n",
      "\n",
      "Classifier: RBF SVM on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 2 19]]\n",
      "Classified incorrectly:  [5, 11, 18] \n",
      "\n",
      "Classifier: Decision Tree on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[18  2]\n",
      " [ 2 18]]\n",
      "Classified incorrectly:  [4, 5, 18, 24] \n",
      "\n",
      "Classifier: Random Forest on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 2 19]]\n",
      "Classified incorrectly:  [5, 11, 24] \n",
      "\n",
      "Classifier: AdaBoost on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[18  1]\n",
      " [ 2 19]]\n",
      "Classified incorrectly:  [4, 5, 24] \n",
      "\n",
      "Classifier: Naive Bayes on Data Set: 2\n",
      "Confusion Matrix: \n",
      "[[17  2]\n",
      " [ 3 18]]\n",
      "Classified incorrectly:  [4, 5, 11, 24, 33] \n",
      "\n",
      "\n",
      "Answers:\n",
      "Total points classified incorrectly (all classifiers):\n",
      "6\n",
      "Point classified incorrectly by all but one classifier:\n",
      "0\n",
      "Prediciton accuracy using majority voting ensemble prediction(all classifiers):\n",
      "0.907\n",
      "\n",
      "Best set of 4 predictors to use to have highest accuracy: \n",
      "['Random Forest', 'RBF SVM', 'Nearest Neighbors', 'Naive Bayes']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import heapq \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "            make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "#This list represents the items that are misclassified in each iteration TOTAL\n",
    "mis_clas_TOTAL = []\n",
    "accuracies = {}\n",
    "\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    \n",
    "    print \"Data Set: \",ds_cnt, \"-\"*20\n",
    "    #This list represents the items that are misclassified in each iteration for each data set\n",
    "    mis_clas_TOTAL = []\n",
    "    mis_clas_list = []\n",
    "    \n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        #This list represents the items that are misclassified in each classifier\n",
    "        mis_clas_indiv = []\n",
    "        clf.fit(X_train, y_train)\n",
    "        print \"Classifier: %s on Data Set: %s\" %(str(name),str(ds_cnt))\n",
    "        score = clf.score(X_test, y_test)\n",
    "        accuracies[str(name)] = score\n",
    "        predict = clf.predict( X_test )\n",
    "        print \"Confusion Matrix: \\n\" ,confusion_matrix(predict,y_test)\n",
    "        #print \"Accuracy: %0.3f\" % score\n",
    "        missing = np.where(y_test != predict)\n",
    "        for i in missing:\n",
    "            for j in i:\n",
    "                mis_clas_indiv.append(j)\n",
    "                mis_clas_TOTAL.append(j)\n",
    "        mis_clas_list.append( list(mis_clas_indiv) )\n",
    "        print \"Classified incorrectly: \" ,mis_clas_indiv, \"\\n\"\n",
    "\n",
    "    print \"\\nAnswers:\"\n",
    "    mis_clas_TOTAL = np.unique(mis_clas_TOTAL)\n",
    "    flat_list = [val for sublist in mis_clas_list for val in sublist]\n",
    "    count = 0\n",
    "    for i in flat_list:\n",
    "        if flat_list.count(i) == 6:\n",
    "            flat_list.remove(i)\n",
    "            #print i\n",
    "            count += 1\n",
    "    print \"Total points classified incorrectly (all classifiers):\\n\", len(mis_clas_TOTAL)\n",
    "    print \"Point classified incorrectly by all but one classifier:\\n\", count\n",
    "    print \"Prediciton accuracy using majority voting ensemble prediction(all classifiers):\\n%0.3f\\n\"% np.array(accuracies.values()).mean()\n",
    "    print \"Best set of 4 predictors to use to have highest accuracy: \\n\", heapq.nlargest(4, accuracies)\n",
    "    print \"\\n\"*2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graduate Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without even having to calculate anything, it is clear by inspection that the best 4 classifiers across all 3 data sets are: \n",
      "['Random Forest', 'RBF SVM', 'Nearest Neighbors', 'Naive Bayes'] \n",
      "\n",
      "These classifiers were ALWAYS the most accurate across all trials\n"
     ]
    }
   ],
   "source": [
    "print \"Without even having to calculate anything, it is clear by inspection that the best 4 classifiers across all \\\n",
    "3 data sets are: \\n\", heapq.nlargest(4, accuracies),\"\\n\\nThese classifiers were ALWAYS the most accurate across all \\\n",
    "trials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set:  0 --------------------\n",
      "K= 1 : cross validation score  = 0.927\n",
      "K= 2 : cross validation score  = 0.927\n",
      "K= 3 : cross validation score  = 0.952\n",
      "K= 4 : cross validation score  = 0.952\n",
      "K= 5 : cross validation score  = 0.927\n",
      "K= 6 : cross validation score  = 0.927\n",
      "K= 7 : cross validation score  = 0.902\n",
      "K= 8 : cross validation score  = 0.877\n",
      "K= 9 : cross validation score  = 0.826\n",
      "K= 10 : cross validation score  = 0.824\n",
      "K= 11 : cross validation score  = 0.852\n",
      "K= 12 : cross validation score  = 0.824\n",
      "K= 13 : cross validation score  = 0.824\n",
      "K= 14 : cross validation score  = 0.848\n",
      "K= 15 : cross validation score  = 0.877\n",
      "K= 16 : cross validation score  = 0.877\n",
      "K= 17 : cross validation score  = 0.877\n",
      "K= 18 : cross validation score  = 0.877\n",
      "K= 19 : cross validation score  = 0.877\n",
      "K= 20 : cross validation score  = 0.877\n",
      "K= 21 : cross validation score  = 0.852\n",
      "K= 22 : cross validation score  = 0.852\n",
      "K= 23 : cross validation score  = 0.852\n",
      "K= 24 : cross validation score  = 0.877\n",
      "K= 25 : cross validation score  = 0.852\n",
      "K= 26 : cross validation score  = 0.877\n",
      "K= 27 : cross validation score  = 0.877\n",
      "K= 28 : cross validation score  = 0.877\n",
      "K= 29 : cross validation score  = 0.927\n",
      "K= 30 : cross validation score  = 0.928\n",
      "\n",
      "Best K-value:  4 \n",
      "\n",
      "Data Set:  1 --------------------\n",
      "K= 1 : cross validation score  = 0.893\n",
      "K= 2 : cross validation score  = 0.949\n",
      "K= 3 : cross validation score  = 0.862\n",
      "K= 4 : cross validation score  = 0.921\n",
      "K= 5 : cross validation score  = 0.633\n",
      "K= 6 : cross validation score  = 0.710\n",
      "K= 7 : cross validation score  = 0.432\n",
      "K= 8 : cross validation score  = 0.478\n",
      "K= 9 : cross validation score  = 0.375\n",
      "K= 10 : cross validation score  = 0.375\n",
      "K= 11 : cross validation score  = 0.375\n",
      "K= 12 : cross validation score  = 0.375\n",
      "K= 13 : cross validation score  = 0.375\n",
      "K= 14 : cross validation score  = 0.375\n",
      "K= 15 : cross validation score  = 0.375\n",
      "K= 16 : cross validation score  = 0.375\n",
      "K= 17 : cross validation score  = 0.375\n",
      "K= 18 : cross validation score  = 0.375\n",
      "K= 19 : cross validation score  = 0.375\n",
      "K= 20 : cross validation score  = 0.375\n",
      "K= 21 : cross validation score  = 0.375\n",
      "K= 22 : cross validation score  = 0.375\n",
      "K= 23 : cross validation score  = 0.375\n",
      "K= 24 : cross validation score  = 0.375\n",
      "K= 25 : cross validation score  = 0.375\n",
      "K= 26 : cross validation score  = 0.375\n",
      "K= 27 : cross validation score  = 0.375\n",
      "K= 28 : cross validation score  = 0.375\n",
      "K= 29 : cross validation score  = 0.375\n",
      "K= 30 : cross validation score  = 0.375\n",
      "\n",
      "Best K-value:  2 \n",
      "\n",
      "Data Set:  2 --------------------\n",
      "K= 1 : cross validation score  = 0.520\n",
      "K= 2 : cross validation score  = 0.437\n",
      "K= 3 : cross validation score  = 0.407\n",
      "K= 4 : cross validation score  = 0.424\n",
      "K= 5 : cross validation score  = 0.479\n",
      "K= 6 : cross validation score  = 0.457\n",
      "K= 7 : cross validation score  = 0.492\n",
      "K= 8 : cross validation score  = 0.516\n",
      "K= 9 : cross validation score  = 0.530\n",
      "K= 10 : cross validation score  = 0.471\n",
      "K= 11 : cross validation score  = 0.504\n",
      "K= 12 : cross validation score  = 0.452\n",
      "K= 13 : cross validation score  = 0.527\n",
      "K= 14 : cross validation score  = 0.506\n",
      "K= 15 : cross validation score  = 0.511\n",
      "K= 16 : cross validation score  = 0.556\n",
      "K= 17 : cross validation score  = 0.503\n",
      "K= 18 : cross validation score  = 0.590\n",
      "K= 19 : cross validation score  = 0.476\n",
      "K= 20 : cross validation score  = 0.594\n",
      "K= 21 : cross validation score  = 0.480\n",
      "K= 22 : cross validation score  = 0.483\n",
      "K= 23 : cross validation score  = 0.402\n",
      "K= 24 : cross validation score  = 0.543\n",
      "K= 25 : cross validation score  = 0.491\n",
      "K= 26 : cross validation score  = 0.599\n",
      "K= 27 : cross validation score  = 0.588\n",
      "K= 28 : cross validation score  = 0.673\n",
      "K= 29 : cross validation score  = 0.625\n",
      "K= 30 : cross validation score  = 0.645\n",
      "\n",
      "Best K-value:  28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "X, y = make_classification(n_features=500, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "            make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    print \"Data Set: \",ds_cnt, \"-\"*20\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    K_list = {}\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "    for i in range(1,31):\n",
    "        KNN = KNeighborsClassifier(i).fit(X_train,y_train)\n",
    "        scores = cross_val_score(KNN, X_test, y_test, cv=5, scoring='f1_macro')\n",
    "        print \"K= %d : cross validation score  = %0.3f\" % (i , scores.mean())\n",
    "        K_list[scores.mean()] = i\n",
    "        x_axis.append(i)\n",
    "        y_axis.append(scores.mean())\n",
    "        \n",
    "    print \"\"\n",
    "    key = np.array(K_list.keys()).max()\n",
    "    print \"Best K-value: \",K_list[key],\"\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Matlab Plot and Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x112d18dd0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI7jOLH4/4cIcyhQZboFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112228450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,31)\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.xlabel(\"K Hyperparamter\")\n",
    "plt.ylabel(\"Cross Validation Score\")\n",
    "plt.title(\"(Third Data Set) K vs Cross Val Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the above example, we see the variation in the cross validation score for the 3rd data set in K-Nearest Neighbor Classifier. As was predicted in the previous section, the cross validation score peaks at K = 28\n"
     ]
    }
   ],
   "source": [
    "print \"In the above example, we see the variation in the cross validation \\\n",
    "score for the 3rd data set in K-Nearest Neighbor Classifier. \\\n",
    "As was predicted in the previous section, the cross validation score peaks \\\n",
    "at K = 28.\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
